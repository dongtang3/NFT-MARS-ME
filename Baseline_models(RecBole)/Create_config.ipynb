{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m'LEE_recbole_2'(으)로 셀을 실행하려면 ipykernel 패키지가 필요합니다.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n LEE_recbole_2 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "SEED = 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip list --format=freeze > ./requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        \n",
    "    # environment\n",
    "    'seed': SEED,\n",
    "    'reproducibility': True,\n",
    "    'data_path': 'dataset/collections/',\n",
    "    'checkpoint_dir': 'saved/',\n",
    "    'show_progress': True,\n",
    "    'save_dataset': False,\n",
    "    'log_wandb': True,\n",
    "    'save_dataloaders': False,\n",
    "    \n",
    "    # data\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    \n",
    "    # training\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 2048, # 2048\n",
    "    'learner': 'adam',\n",
    "    'learning_rate': 0.001, # 0.001\n",
    "    'train_neg_sample_args': {'distribution': 'popularity',\n",
    "                              'sample_num': 5,\n",
    "                              'dynamic': False,\n",
    "                              'candidate_num': 0},\n",
    "    'eval_step': 1,\n",
    "    'stopping_step': 3000, # 15\n",
    "    'loss_decimal_place': 4,\n",
    "    \n",
    "    # evaluation\n",
    "    'eval_args': {'group_by': 'user',\n",
    "                #   'order': 'MY',\n",
    "                #   'split': {'MY':'dataset/collections/azuki/split_indices.pkl'},\n",
    "                  'mode': 'pop100'},\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'MAP', 'Precision', 'GAUC'],\n",
    "    'topk': [10, 20, 50], \n",
    "    'valid_metric': 'Recall@50', # for early stopping\n",
    "    'eval_batch_size': 4096, # 4096\n",
    "    'metric_decimal_place': 4\n",
    "    \n",
    "}\n",
    "\n",
    "# convert parameter_dict to yaml file\n",
    "with open(r'config/fixed_config_general.yaml', 'w') as file:\n",
    "    documents = yaml.dump(parameter_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {\n",
    "        \n",
    "    # environment\n",
    "    'seed': SEED,\n",
    "    'reproducibility': True,\n",
    "    'data_path': 'dataset/collections/',\n",
    "    'checkpoint_dir': 'saved/',\n",
    "    'show_progress': True,\n",
    "    'save_dataset': False,\n",
    "    'log_wandb': True,\n",
    "    'save_dataloaders': False,\n",
    "    \n",
    "    # data\n",
    "    'field_separator': '\\t',\n",
    "    'seq_separator': ' ',\n",
    "    'USER_ID_FIELD': 'user_id',\n",
    "    'ITEM_ID_FIELD': 'item_id',\n",
    "    'load_col' : {'inter': ['user_id', 'item_id'],\n",
    "                  'item': ['item_id', 'img', 'txt', 'price', 'txn'],\n",
    "                  'user': ['user_id', 'num_txn', 'avg_price', 'hold_period']},\n",
    "    \n",
    "    # training\n",
    "    'epochs': 50,\n",
    "    'train_batch_size': 2048, # 2048\n",
    "    'learner': 'adam',\n",
    "    'learning_rate': 0.001, # 0.001\n",
    "    'train_neg_sample_args': {'distribution': 'popularity',\n",
    "                              'sample_num': 5,\n",
    "                              'dynamic': False,\n",
    "                              'candidate_num': 0},\n",
    "    'eval_step': 1,\n",
    "    'stopping_step': 3000, # 15\n",
    "    'loss_decimal_place': 4,\n",
    "    \n",
    "    # evaluation\n",
    "    'eval_args': {'group_by': 'user',\n",
    "                #   'order': 'MY',\n",
    "                #   'split': {'MY':'dataset/collections/azuki/split_indices.pkl'},\n",
    "                  'mode': 'pop100'},\n",
    "    'metrics': ['Recall', 'MRR', 'NDCG', 'Hit', 'MAP', 'Precision', 'GAUC'],\n",
    "    'topk': [10, 20, 50], \n",
    "    'valid_metric': 'Recall@50', # for early stopping\n",
    "    'eval_batch_size': 4096, # 4096\n",
    "    'metric_decimal_place': 4\n",
    "    \n",
    "}\n",
    "\n",
    "# convert parameter_dict to yaml file\n",
    "with open(r'config/fixed_config_context.yaml', 'w') as file:\n",
    "    documents = yaml.dump(parameter_dict, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.utils import init_seed, init_logger\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.utils import get_model, get_trainer\n",
    "# from recbole.trainer import HyperTuning\n",
    "# from recbole.quick_start import objective_function\n",
    "from recbole.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_names = ['FM'] # ['BPR', 'DMF', 'NeuMF', 'NGCF', 'LightGCN'] ['FM', 'NFM', 'DeepFM', 'AFM', 'WideDeep', 'AutoInt', 'DCN']\n",
    "DATASET_names = ['bayc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m logger \u001b[39m=\u001b[39m getLogger()\n\u001b[1;32m     16\u001b[0m \u001b[39m# dataset creating and filtering # convert atomic files -> Dataset\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m dataset \u001b[39m=\u001b[39m create_dataset(config)\n\u001b[1;32m     18\u001b[0m logger\u001b[39m.\u001b[39minfo(dataset) \u001b[39m# print dataset info\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# dataset splitting # convert Dataset -> Dataloader\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/recbole/data/utils.py:70\u001b[0m, in \u001b[0;36mcreate_dataset\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     67\u001b[0m         logger\u001b[39m.\u001b[39minfo(set_color(\u001b[39m\"\u001b[39m\u001b[39mLoad filtered dataset from\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mpink\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m: [\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     68\u001b[0m         \u001b[39mreturn\u001b[39;00m dataset\n\u001b[0;32m---> 70\u001b[0m dataset \u001b[39m=\u001b[39m dataset_class(config)\n\u001b[1;32m     71\u001b[0m \u001b[39mif\u001b[39;00m config[\u001b[39m\"\u001b[39m\u001b[39msave_dataset\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m     72\u001b[0m     dataset\u001b[39m.\u001b[39msave()\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:108\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, config)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name \u001b[39m=\u001b[39m config[\u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    107\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger \u001b[39m=\u001b[39m getLogger()\n\u001b[0;32m--> 108\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_from_scratch()\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:120\u001b[0m, in \u001b[0;36mDataset._from_scratch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_data(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_path)\n\u001b[1;32m    119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_alias()\n\u001b[0;32m--> 120\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_processing()\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:166\u001b[0m, in \u001b[0;36mDataset._data_processing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_remap_ID_all()\n\u001b[1;32m    165\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user_item_feat_preparation()\n\u001b[0;32m--> 166\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fill_nan()\n\u001b[1;32m    167\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_label_by_threshold()\n\u001b[1;32m    168\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_normalize()\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/recbole/data/dataset/dataset.py:642\u001b[0m, in \u001b[0;36mDataset._fill_nan\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    640\u001b[0m     feat[field]\u001b[39m.\u001b[39mfillna(value\u001b[39m=\u001b[39mfeat[field]\u001b[39m.\u001b[39mmean(), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    641\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 642\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint64 \u001b[39mif\u001b[39;00m ftype \u001b[39m==\u001b[39m FeatureType\u001b[39m.\u001b[39mTOKEN_SEQ \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39;49mfloat\n\u001b[1;32m    643\u001b[0m     feat[field] \u001b[39m=\u001b[39m feat[field]\u001b[39m.\u001b[39mapply(\n\u001b[1;32m    644\u001b[0m         \u001b[39mlambda\u001b[39;00m x: np\u001b[39m.\u001b[39marray([], dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    645\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x, \u001b[39mfloat\u001b[39m)\n\u001b[1;32m    646\u001b[0m         \u001b[39melse\u001b[39;00m x\n\u001b[1;32m    647\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/LEE_recbole/lib/python3.11/site-packages/numpy/__init__.py:305\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    300\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    301\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    307\u001b[0m \u001b[39m# Importing Tester requires importing all of UnitTest which is not a\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39m# cheap import Since it is mainly used in test suits, we lazy import it\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[39m# here to save on the order of 10 ms of import time for most users\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# The previous way Tester was imported also had a side effect of adding\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# the full `numpy.testing` namespace\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    for MODEL in tqdm(MODEL_names):\n",
    "        test_result_list = []\n",
    "        for DATASET in DATASET_names:\n",
    "            \n",
    "            config = Config(model=MODEL, dataset=DATASET, config_file_list=['config/fixed_config_context.yaml'])\n",
    "            \n",
    "            # init random seed\n",
    "            init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "            # logger initialization\n",
    "            init_logger(config)\n",
    "            logger = getLogger()\n",
    "\n",
    "            # dataset creating and filtering # convert atomic files -> Dataset\n",
    "            dataset = create_dataset(config)\n",
    "            logger.info(dataset) # print dataset info\n",
    "\n",
    "            # dataset splitting # convert Dataset -> Dataloader\n",
    "            train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "\n",
    "            # model loading and initialization\n",
    "            model = get_model(config['model'])(config, train_data.dataset).to(config['device'])\n",
    "            logger.info(model)\n",
    "\n",
    "            # trainer loading and initialization\n",
    "            trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "            \n",
    "\n",
    "            \"\"\" (1) training \"\"\"\n",
    "            \n",
    "            # model training\n",
    "            best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)\n",
    "\n",
    "\n",
    "            \"\"\" (2) testing \"\"\"\n",
    "\n",
    "            # When calculate ItemCoverage metrics, we need to run this code for set item_nums in eval_collector.\n",
    "            trainer.eval_collector.data_collect(train_data)\n",
    "\n",
    "            # model evaluation\n",
    "            test_result = trainer.evaluate(test_data)\n",
    "            print('FINAL TEST RESULT')\n",
    "            print(test_result)\n",
    "            test_result_list.append(pd.DataFrame.from_dict(test_result, orient='index', columns=[DATASET]))\n",
    "                "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_function(config_dict=None, config_file_list=None):\n",
    "    \n",
    "    config = Config(model=MODEL, dataset=DATASET, config_dict=config_dict, config_file_list=config_file_list)\n",
    "    init_seed(config['seed'], config['reproducibility'])\n",
    "    dataset = create_dataset(config)\n",
    "    train_data, valid_data, test_data = data_preparation(config, dataset)\n",
    "    model_name = config['model']\n",
    "    model = get_model(model_name)(config, train_data.dataset).to(config['device'])\n",
    "    trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)\n",
    "    \"\"\" (1) training \"\"\"\n",
    "    best_valid_score, best_valid_result = trainer.fit(train_data, valid_data, verbose=False)\n",
    "    \"\"\" (2) testing \"\"\"\n",
    "    test_result = trainer.evaluate(test_data)\n",
    "\n",
    "    return {\n",
    "        'model': model_name,\n",
    "        'best_valid_score': best_valid_score,\n",
    "        'valid_score_bigger': config['valid_metric_bigger'],\n",
    "        'best_valid_result': best_valid_result,\n",
    "        'test_result': test_result\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_names = ['NGCF']\n",
    "DATASET_names = ['meebits']\n",
    "ITEM_CUT_list = [3]\n",
    "\n",
    "result_path = './result/'\n",
    "# create folder result_path\n",
    "if not os.path.exists(result_path):\n",
    "    os.makedirs(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MODEL_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18296\\795344120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mMODEL_names\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mDATASET\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATASET_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mHPO_test_result_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mITEM_CUT\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mITEM_CUT_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MODEL_names' is not defined"
     ]
    }
   ],
   "source": [
    "for MODEL in MODEL_names:\n",
    "    for DATASET in tqdm(DATASET_names):\n",
    "        HPO_test_result_list = []\n",
    "        for ITEM_CUT in ITEM_CUT_list:\n",
    "            \n",
    "            hp = HyperTuning(objective_function=objective_function, algo='exhaustive', \n",
    "                                max_evals=50, params_file=f'hyper/{MODEL}.hyper', fixed_config_file_list=['config/fixed_config_baseline.yaml'])\n",
    "\n",
    "            # run\n",
    "            hp.run()\n",
    "            # export result to the file\n",
    "            hp.export_result(output_file=f'hyper/{MODEL}_{DATASET}_{ITEM_CUT}.result')\n",
    "            # print best parameters\n",
    "            print('best params: ', hp.best_params)\n",
    "            # save best parameters\n",
    "            with open(f'hyper/{MODEL}_{DATASET}_{ITEM_CUT}.best_params', 'w') as file:\n",
    "                documents = yaml.dump(hp.best_params, file)\n",
    "            # print best result\n",
    "            best_result = hp.params2result[hp.params2str(hp.best_params)]\n",
    "            print('best result: ')\n",
    "            print(best_result)\n",
    "            \n",
    "            HPO_test_result_list.append(pd.DataFrame.from_dict(best_result['test_result'], orient='index', columns=[f'{DATASET}_{ITEM_CUT}'])) \n",
    "        \n",
    "        pd.concat(HPO_test_result_list, axis=1).to_csv(result_path + f'{MODEL}_{DATASET}_{ITEM_CUT}.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecBole_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "991fe3f9de00c9a422a5f66b8cc7243158afe66a42c9654a2fcf9d740859f175"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
